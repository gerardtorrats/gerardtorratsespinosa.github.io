---
title: "Examples of Bayesian Applications"
subtitle: ""
author:  
date: ""
output:
  html_document:
    number_sections: false
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: true
---

<style type="text/css">

h1.title { /* Title */
    font-size: 24px;
    color: DarkBlue;
    font-weight: bold;
    font-style: normal;
}
h3.subtitle { /* Subtitle */
    font-size: 20px;
    color: DarkBlue;
    font-weight: normal;
    font-style: normal;
}
h4.author { /* Author */
    font-size: 16px;
    color: Gray;
    font-weight: normal;
    font-style: normal;
}
h4.date { /* Date */
    font-size: 14px;
    color: Gray;
    font-weight: normal;
    font-style: italic;
}


h1 { /* Header 1 */
    font-size: 20px;
    color: DarkBlue;
    font-weight: bold; <!-- this could be:  font-weight: bold -->
    font-style: normal;
}
h2 { /* Header 2 */
    font-size: 18px;
    color: DarkBlue;
    font-weight: bold;
    font-style: normal;
}
h3 { /* Header 3 */
    font-size: 16px;
    color: DarkBlue;
    font-weight: normal;
    font-style: normal;
}
h4 { /* Header 4 */
    font-size: 14px;
    color: DarkBlue;
    font-weight: normal;
    font-style: normal;
}
h5 { /* Header 5 */
    font-size: 12px;
    color: Black;
    font-weight: normal;
    font-style: normal;
}


body{ /* Normal  */
      font-size: 12px;
      font-family: "Verdana", Times, serif;
  }
td {  /* Table  */
  font-size: 8px;
}


code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 12px;
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Example 1: Bayes Rule


You go to the doctor for a COVID-19 rapid test. Let `theta` represent your true state: `theta` = 1 if you are infected with the virus, and `theta` = 0 if you are not. Let `y` denote the result of the test: `y` = 1 if the test comes back positive and `y` = 0 if the test is negative. The probability of a correct result for an infected subject is called the sensitivity of the test (`Pr(y=1|theta=1)`), we will denote it `p` here. The probability of correct result for one not infected with the virus is called the specificity (`Pr(Y=0|theta=0)`), denoted as `q.`  

Do you have the virus? Of course you donâ€™t know. In Bayesian statistics we describe our uncertainty about the world by assigning probabilities to various states. Suppose your prior probability
of being infected is `pi`. That is, the marginal probability `Pr(theta = 1) = pi` .

With this information we can define the following:

- `pi`  as the prior prob of infection ("prevalence"): `pi = Pr(theta=1)`
- `q0` is the false positive probability: `q0 = Pr(Y=1|theta=0)`
- `q1` is the true positive probability: `q1 = Pr(Y=1|theta=1)`. This is also called the sensitivity of the test; `1-q0` is the specificity of the test.


We set the following values in R:
```{r}
pi <- .04   # 20% of population is infected
q1 <- .90  # test has sensitivity of .90
q0 <- .08  # test has specificity of .92
```


With this we can compute the posterior probabilities, given test result. 

The probability of infection, before the test result is available is `pi`:
```{r}
pi  # Prob of infection, before test result is available 

```

The probability of infection given a positive test is:
$$Pr(\theta|y_1 =1) = \frac{Pr(\theta = 1, y_1 = 1)}{Pr(y_1=1)} = \frac{Pr(\theta=1)Pr(y_1=1|\theta=1)}{Pr(y_1=1)} = \frac{\pi p }{\pi p + (1-\pi)q}$$


```{r}

pi * q1 / (pi*q1 + (1-pi)*q0)  # Prob of infection given positive test result

```

The probability of infection given a negative test is:
$$Pr(\theta|y_1 =0) = \frac{Pr(\theta = 1, y_1 = 1)}{Pr(y_1=0)} = \frac{Pr(\theta=1)Pr(y_1=0|\theta=1)}{Pr(y_1=0)} = \frac{\pi (1-p) }{\pi (1-p) + (1-\pi)(1-q)}$$

```{r}

pi*(1-q1) / (pi*(1-q1) + (1-pi)*(1-q0))  # Prob of infection if test negative
```

Plot posterior probability versus prior probability:

```{r}
post.prob <- function(pi, q0, q1)
{
  pi * q1 / (pi*q1 + (1-pi)*q0)
}

grid <- seq(.01, .99, .01)

plot(grid, post.prob(pi=grid, q0=q0, q1=q1), type="l", 
     xlab="Prior probability", ylab="Posterior prob", 
     main="Prob of infection given positive test", ylim=c(0,1))
```

That's how the posterior prob varies with prior prob

What about the sensitivity and specificity of the test?

```{r}
op <- par(mfrow=c(1,2))

plot(grid, post.prob(pi=pi, q1=grid, q0=q0), type="l", 
     xlab="Sensitivity of test", ylab="Posterior prob", 
     main="Prob of infection given positive test", ylim=c(0,1))

plot(grid, post.prob(pi=pi, q1=q1, q0=1-grid), type="l",
     xlab="Specificity of test", ylab="Posterior prob", 
     main="Prob of infection given positive test", ylim=c(0,1))

par(op)
```
 
### Monte Carlo approximation 
Simulate the joint distribution of theta and Y:
```{r}

S <- 1000;  theta <- NULL;  y <- NULL;

for(s in 1:S)
{
  theta[s] <- rbinom(1, 1, pi)
  prob <- ifelse(theta[s]==1, q1, q0)
  y[s] <- rbinom(1, 1, prob)
}

table(theta, y) / S  # approximate joint distribution

mean(theta[y==1])  #  Monte Carlo approx to posterior prob
```


Of course there's no real need for Monte Carlo, when the exact  joint distribution is available by straightforward calculation:
```{r}

joint <- matrix(c((1-pi)*(1-q0), pi*(1-q1), (1-pi)*q0, pi*q1), 2,2)

rownames(joint) <- c("theta=0", "theta=1")

colnames(joint) <- c("y=0", "y=1")

joint

joint[2,2] / sum(joint[,2])
```

